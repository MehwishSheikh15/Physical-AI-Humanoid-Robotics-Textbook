"use strict";(globalThis.webpackChunkai_robotics_book=globalThis.webpackChunkai_robotics_book||[]).push([[7399],{8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(6540);const a={},r=s.createContext(a);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(r.Provider,{value:n},e.children)}},9365:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Module-3-ISSAC/week-08-isaac-intro","title":"Week 8: NVIDIA Isaac Platform Introduction","description":"Discover the NVIDIA Isaac ecosystem: Isaac Sim for photorealistic simulation, Isaac SDK for perception, and synthetic data generation for training AI models.","source":"@site/docs/Module-3-ISSAC/week-08-isaac-intro.mdx","sourceDirName":"Module-3-ISSAC","slug":"/Module-3-ISSAC/week-08-isaac-intro","permalink":"/ai-robotics-book/docs/Module-3-ISSAC/week-08-isaac-intro","draft":false,"unlisted":false,"editUrl":"https://github.com/ai-robotics/ai-robotics-book/tree/main/docs/Module-3-ISSAC/week-08-isaac-intro.mdx","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"title":"Week 8: NVIDIA Isaac Platform Introduction","description":"Discover the NVIDIA Isaac ecosystem: Isaac Sim for photorealistic simulation, Isaac SDK for perception, and synthetic data generation for training AI models."},"sidebar":"tutorialSidebar","previous":{"title":"Week 7: URDF Modeling and Simulation","permalink":"/ai-robotics-book/docs/Module-2-GAZEBO/week-07-urdf-modeling"},"next":{"title":"Week 8: NVIDIA Isaac Platform Introduction","permalink":"/ai-robotics-book/docs/Module-3-ISSAC/week-08-isaac-intro"}}');var a=i(4848),r=i(8453);const t={sidebar_position:8,title:"Week 8: NVIDIA Isaac Platform Introduction",description:"Discover the NVIDIA Isaac ecosystem: Isaac Sim for photorealistic simulation, Isaac SDK for perception, and synthetic data generation for training AI models."},o="Week 8: NVIDIA Isaac Platform Introduction",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"The NVIDIA Isaac Ecosystem",id:"the-nvidia-isaac-ecosystem",level:2},{value:"Three Pillars",id:"three-pillars",level:3},{value:"Why Isaac Over Gazebo?",id:"why-isaac-over-gazebo",level:3},{value:"Installing Isaac Sim",id:"installing-isaac-sim",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Installation Steps",id:"installation-steps",level:3},{value:"Verifying Installation",id:"verifying-installation",level:3},{value:"Isaac Sim Basics",id:"isaac-sim-basics",level:2},{value:"USD: Universal Scene Description",id:"usd-universal-scene-description",level:3},{value:"Creating a Simple Scene",id:"creating-a-simple-scene",level:3},{value:"Adding a Robot",id:"adding-a-robot",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Why Synthetic Data?",id:"why-synthetic-data",level:3},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"Code Example: Generating a Dataset",id:"code-example-generating-a-dataset",level:3},{value:"ROS 2 Integration",id:"ros-2-integration",level:2},{value:"Isaac ROS Bridge",id:"isaac-ros-bridge",level:3},{value:"Launch File for Isaac Sim + ROS 2",id:"launch-file-for-isaac-sim--ros-2",level:3},{value:"Isaac Sim vs Real World: Sim-to-Real",id:"isaac-sim-vs-real-world-sim-to-real",level:2},{value:"Bridging the Gap",id:"bridging-the-gap",level:3},{value:"Code Example: Adding Realistic Camera Noise",id:"code-example-adding-realistic-camera-noise",level:3},{value:"Self-Assessment Questions",id:"self-assessment-questions",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components},{Details:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"week-8-nvidia-isaac-platform-introduction",children:"Week 8: NVIDIA Isaac Platform Introduction"})}),"\n",(0,a.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsxs)(n.p,{children:["While Gazebo excels at general-purpose robot simulation, ",(0,a.jsx)(n.strong,{children:"NVIDIA Isaac"})," is purpose-built for AI-powered robotics at scale. Isaac Sim delivers photorealistic rendering, accurate physics, and massive parallelization on NVIDIA GPUs. Isaac SDK provides production-ready perception, navigation, and manipulation algorithms optimized for NVIDIA hardware."]}),"\n",(0,a.jsx)(n.p,{children:'The Isaac platform is NVIDIA\'s answer to the question: "How do we train, simulate, and deploy millions of robots with AI perception?" From warehouse automation to humanoid robots, Isaac powers the next generation of intelligent physical systems.'}),"\n",(0,a.jsx)(n.p,{children:"This week introduces the Isaac ecosystem, installation, Isaac Sim basics, and synthetic data generation\u2014the secret weapon for training robust vision models without manual labeling."}),"\n",(0,a.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this week, you will be able to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Understand"})," the Isaac ecosystem (Sim, SDK, ROS/ROS 2 integration)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Install"})," Isaac Sim on Ubuntu 22.04 with RTX 4070 Ti GPU support"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Create"})," simple scenes in Isaac Sim with USD (Universal Scene Description)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Generate"})," synthetic datasets for object detection and segmentation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Integrate"})," Isaac Sim with ROS 2 for sensor data streaming"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"the-nvidia-isaac-ecosystem",children:"The NVIDIA Isaac Ecosystem"}),"\n",(0,a.jsx)(n.h3,{id:"three-pillars",children:"Three Pillars"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Isaac Sim"}),": Photorealistic robot simulator built on Omniverse"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Physically accurate rendering (ray tracing, global illumination)"}),"\n",(0,a.jsx)(n.li,{children:"RTX-accelerated physics (PhysX 5)"}),"\n",(0,a.jsx)(n.li,{children:"Domain randomization for robust AI training"}),"\n",(0,a.jsx)(n.li,{children:"Multi-robot simulation (hundreds of robots in parallel)"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Isaac SDK/GEMs"}),": Perception and navigation libraries"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Isaac ROS: ROS 2 packages (VSLAM, depth perception, object detection)"}),"\n",(0,a.jsx)(n.li,{children:"Pre-trained AI models (PeopleNet, TrafficCamNet)"}),"\n",(0,a.jsx)(n.li,{children:"Optimized for Jetson (edge) and RTX (workstation)"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Isaac Manipulator/Navigation"}),": Application frameworks"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"cuRobot: GPU-accelerated motion planning"}),"\n",(0,a.jsx)(n.li,{children:"cuMotion: Collision-free trajectory optimization"}),"\n",(0,a.jsx)(n.li,{children:"cuOpt: Fleet management and task allocation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-mermaid",children:'graph TB\n    subgraph "Isaac Platform Stack"\n        Apps["Applications<br/>(Your Robot)"]\n        IsaacROS["Isaac ROS<br/>(VSLAM, Detection, Nav)"]\n        IsaacSim["Isaac Sim<br/>(Training & Testing)"]\n        SDK["Isaac SDK/GEMs<br/>(cuMotion, cuOpt)"]\n        TensorRT["TensorRT<br/>(AI Inference)"]\n        CUDA["CUDA<br/>(GPU Compute)"]\n        Hardware["NVIDIA Hardware<br/>(Jetson, RTX)"]\n    end\n\n    Apps --\x3e IsaacROS\n    Apps --\x3e SDK\n    IsaacROS --\x3e TensorRT\n    SDK --\x3e TensorRT\n    IsaacSim --\x3e TensorRT\n    TensorRT --\x3e CUDA\n    CUDA --\x3e Hardware\n\n    style IsaacROS fill:#a855f7,stroke:#9333ea,stroke-width:2px,color:#fff\n    style IsaacSim fill:#ec4899,stroke:#db2777,stroke-width:2px,color:#fff\n    style TensorRT fill:#06b6d4,stroke:#0891b2,stroke-width:2px,color:#fff\n'})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Diagram:"})," NVIDIA Isaac platform architecture showing how applications leverage Isaac ROS and SDK components, all optimized through TensorRT and CUDA for NVIDIA hardware."]}),"\n",(0,a.jsx)(n.h3,{id:"why-isaac-over-gazebo",children:"Why Isaac Over Gazebo?"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Feature"}),(0,a.jsx)(n.th,{children:"Gazebo"}),(0,a.jsx)(n.th,{children:"Isaac Sim"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Rendering"})}),(0,a.jsx)(n.td,{children:"Basic (OpenGL)"}),(0,a.jsx)(n.td,{children:"Photorealistic (RTX ray tracing)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Physics"})}),(0,a.jsx)(n.td,{children:"CPU (ODE/Bullet)"}),(0,a.jsx)(n.td,{children:"GPU-accelerated (PhysX 5)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Scale"})}),(0,a.jsx)(n.td,{children:"~10 robots"}),(0,a.jsx)(n.td,{children:"100+ robots (GPU parallelization)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"AI Training"})}),(0,a.jsx)(n.td,{children:"Limited"}),(0,a.jsx)(n.td,{children:"Synthetic data generation, domain randomization"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Hardware Req"})}),(0,a.jsx)(n.td,{children:"Modest"}),(0,a.jsx)(n.td,{children:"NVIDIA RTX GPU (2070+)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Use Case"})}),(0,a.jsx)(n.td,{children:"General robotics"}),(0,a.jsx)(n.td,{children:"AI-heavy, large-scale deployments"})]})]})]}),"\n",(0,a.jsx)("div",{className:"neon-border",children:(0,a.jsxs)("p",{children:[(0,a.jsx)("strong",{children:"Key Insight"}),": Isaac Sim's photorealistic rendering enables training vision models on synthetic data that generalize to the real world. This dramatically reduces the need for manual data labeling\u2014a bottleneck in traditional robotics development."]})}),"\n",(0,a.jsx)(n.h2,{id:"installing-isaac-sim",children:"Installing Isaac Sim"}),"\n",(0,a.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"OS"}),": Ubuntu 20.04/22.04 (Linux required)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"GPU"}),": NVIDIA RTX 2070 or better (RTX 4070 Ti recommended)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"VRAM"}),": 8GB minimum (16GB+ for complex scenes)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"RAM"}),": 32GB recommended"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Storage"}),": 50GB+ for Isaac Sim and assets"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"installation-steps",children:"Installation Steps"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'# 1. Install NVIDIA Driver (if not already installed)\nsudo apt install nvidia-driver-535  # Or latest stable version\nnvidia-smi  # Verify GPU is detected\n\n# 2. Download Isaac Sim from NVIDIA\n# Visit: https://developer.nvidia.com/isaac-sim\n# Download "Isaac Sim 2023.1.1" (or latest) Workstation version\n\n# 3. Extract and run installer\ncd ~/Downloads\ntar -xf isaac-sim-2023.1.1-ubuntu22.04.tar.gz\ncd isaac-sim-2023.1.1\n./isaac-sim.sh  # First launch takes 5-10 minutes (downloads assets)\n\n# 4. Install Isaac ROS (for ROS 2 Humble integration)\nsudo apt install ros-humble-isaac-ros-common\n'})}),"\n",(0,a.jsx)(n.admonition,{type:"warning",children:(0,a.jsx)(n.p,{children:"Isaac Sim requires an NVIDIA GPU. It will not run on AMD/Intel GPUs or in CPU-only mode. If you don't have an RTX GPU, use NVIDIA Omniverse Cloud for remote access (requires account)."})}),"\n",(0,a.jsx)(n.h3,{id:"verifying-installation",children:"Verifying Installation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'# Launch Isaac Sim\n./isaac-sim.sh\n\n# In Isaac Sim GUI:\n# File \u2192 Open \u2192 Select "simple_warehouse.usd" example\n# Press Play (bottom-left) to start simulation\n# You should see physics running at 60 FPS\n'})}),"\n",(0,a.jsx)(n.h2,{id:"isaac-sim-basics",children:"Isaac Sim Basics"}),"\n",(0,a.jsx)(n.h3,{id:"usd-universal-scene-description",children:"USD: Universal Scene Description"}),"\n",(0,a.jsxs)(n.p,{children:["Isaac Sim uses ",(0,a.jsx)(n.strong,{children:"USD (Universal Scene Description)"}),", Pixar's open-source framework for 3D scenes. Unlike URDF (XML), USD is:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Composable"}),": Layers combine to form final scene"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Non-destructive"}),": Edit without modifying original files"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"High-performance"}),": Optimized for large scenes"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"creating-a-simple-scene",children:"Creating a Simple Scene"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# simple_scene.py - Create a scene programmatically\n\nfrom omni.isaac.kit import SimulationApp\n\n# Start Isaac Sim headless (no GUI) or with GUI\nsimulation_app = SimulationApp({"headless": False})\n\nfrom omni.isaac.core import World\nfrom omni.isaac.core.objects import DynamicCuboid\nfrom omni.isaac.core.prims import XFormPrim\nimport numpy as np\n\n# Create a simulation world\nworld = World(stage_units_in_meters=1.0)\n\n# Add ground plane\nworld.scene.add_default_ground_plane()\n\n# Add a dynamic cube (will fall due to gravity)\ncube = world.scene.add(\n    DynamicCuboid(\n        prim_path="/World/Cube",\n        name="red_cube",\n        position=np.array([0, 0, 2.0]),  # 2 meters above ground\n        scale=np.array([0.5, 0.5, 0.5]),  # 50cm cube\n        color=np.array([1.0, 0.0, 0.0])   # Red\n    )\n)\n\n# Reset simulation\nworld.reset()\n\n# Run simulation for 500 steps\nfor i in range(500):\n    world.step(render=True)  # Step physics and render\n\n# Clean up\nsimulation_app.close()\n'})}),"\n",(0,a.jsx)(n.p,{children:"Run with:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"./isaac-sim.sh --python simple_scene.py\n"})}),"\n",(0,a.jsx)(n.p,{children:"You'll see a red cube fall and bounce on the ground plane!"}),"\n",(0,a.jsx)(n.h3,{id:"adding-a-robot",children:"Adding a Robot"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from omni.isaac.core.robots import Robot\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\n\n# Load a robot from USD file\nadd_reference_to_stage(\n    usd_path="/Isaac/Robots/Carter/carter_v2.usd",  # Built-in Carter robot\n    prim_path="/World/Carter"\n)\n\n# Create robot object\ncarter = world.scene.add(Robot(prim_path="/World/Carter", name="carter_robot"))\n\nworld.reset()\n\n# Apply velocity command\ncarter.set_joint_velocities(velocities=[1.0, 1.0])  # Move forward\n\nfor i in range(1000):\n    world.step(render=True)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,a.jsx)(n.h3,{id:"why-synthetic-data",children:"Why Synthetic Data?"}),"\n",(0,a.jsx)(n.p,{children:"Training object detection models requires thousands of labeled images. Manual labeling is:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Expensive"}),": $0.10-$1.00 per image"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Time-consuming"}),": Weeks to months"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Limited"}),": Hard to cover edge cases (rain, night, occlusions)"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Synthetic data"})," in Isaac Sim:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Generate 10,000 labeled images in hours"}),"\n",(0,a.jsx)(n.li,{children:"Perfect labels (bounding boxes, segmentation masks, depth)"}),"\n",(0,a.jsx)(n.li,{children:"Infinite variety (lighting, textures, poses)"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)("span",{className:"highlight-purple",children:(0,a.jsx)(n.strong,{children:"Domain randomization"})})," varies scene properties to prevent overfitting:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Lighting"}),": Vary intensity, color temperature, shadows"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Textures"}),": Random materials on objects"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Camera"}),": Different angles, exposures, noise"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Backgrounds"}),": Change wall colors, add clutter"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"This forces models to learn robust features that work in the real world."}),"\n",(0,a.jsx)(n.h3,{id:"code-example-generating-a-dataset",children:"Code Example: Generating a Dataset"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from omni.isaac.kit import SimulationApp\nsimulation_app = SimulationApp({"headless": True})  # No GUI for faster generation\n\nfrom omni.isaac.core import World\nfrom omni.isaac.core.objects import DynamicCuboid\nfrom omni.isaac.synthetic_utils import SyntheticDataHelper\nfrom omni.replicator.core import AnnotatorRegistry\nimport omni.replicator.core as rep\nimport numpy as np\n\nworld = World()\nworld.scene.add_default_ground_plane()\n\n# Add camera\ncamera_prim = rep.create.camera(position=(3, 0, 1), look_at=(0, 0, 0.5))\n\n# Add objects with random positions\nfor i in range(10):\n    cube = world.scene.add(\n        DynamicCuboid(\n            prim_path=f"/World/Cube_{i}",\n            position=np.random.uniform(-2, 2, size=3),\n            scale=np.random.uniform(0.1, 0.5, size=3),\n            color=np.random.rand(3)\n        )\n    )\n\n# Set up synthetic data writer\noutput_dir = "/tmp/synthetic_data"\nwriter = rep.WriterRegistry.get("BasicWriter")\nwriter.initialize(output_dir=output_dir, rgb=True, bounding_box_2d_tight=True)\n\n# Generate 100 frames with domain randomization\nfor i in range(100):\n    # Randomize lighting\n    rep.randomizer.set_lights(\n        intensity=np.random.uniform(500, 2000),\n        temperature=np.random.uniform(3000, 6500)\n    )\n\n    # Step simulation\n    world.step(render=True)\n\n    # Capture annotated data\n    writer.write({"step": i})\n\n    if i % 10 == 0:\n        print(f"Generated {i}/100 images")\n\nprint(f"Dataset saved to {output_dir}")\nsimulation_app.close()\n'})}),"\n",(0,a.jsx)(n.p,{children:"Output includes:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"rgb_0000.png"}),", ",(0,a.jsx)(n.code,{children:"rgb_0001.png"}),", ... (color images)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"bounding_box_2d_tight_0000.json"})," (object detection labels)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"semantic_segmentation_0000.png"})," (pixel-wise labels)"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"ros-2-integration",children:"ROS 2 Integration"}),"\n",(0,a.jsx)(n.h3,{id:"isaac-ros-bridge",children:"Isaac ROS Bridge"}),"\n",(0,a.jsx)(n.p,{children:"Isaac Sim can publish sensor data directly to ROS 2 topics:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from omni.isaac.core.utils.extensions import enable_extension\n\n# Enable ROS 2 bridge extension\nenable_extension("omni.isaac.ros2_bridge")\n\n# In Isaac Sim GUI:\n# Add camera to robot\n# Right-click camera \u2192 Add \u2192 Isaac \u2192 ROS 2 \u2192 RGB\n# This creates a ROS 2 publisher for /camera/image_raw\n\n# Now in a separate terminal:\nros2 topic echo /camera/image_raw  # See images from Isaac Sim!\n'})}),"\n",(0,a.jsx)(n.h3,{id:"launch-file-for-isaac-sim--ros-2",children:"Launch File for Isaac Sim + ROS 2"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# launch/isaac_sim_ros2.launch.py\n\nfrom launch import LaunchDescription\nfrom launch.actions import ExecuteProcess\nfrom launch_ros.actions import Node\n\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # Start Isaac Sim with specific scene\n        ExecuteProcess(\n            cmd=[\n                '/path/to/isaac-sim.sh',\n                '--python', '/path/to/scene.py'\n            ],\n            output='screen'\n        ),\n\n        # Start image processing node\n        Node(\n            package='my_robot_pkg',\n            executable='object_detector',\n            name='detector',\n            remappings=[('/image', '/camera/image_raw')],\n            output='screen'\n        ),\n    ])\n"})}),"\n",(0,a.jsx)(n.h2,{id:"isaac-sim-vs-real-world-sim-to-real",children:"Isaac Sim vs Real World: Sim-to-Real"}),"\n",(0,a.jsx)(n.h3,{id:"bridging-the-gap",children:"Bridging the Gap"}),"\n",(0,a.jsx)(n.p,{children:"Even with photorealistic rendering, sim-to-real transfer requires:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Accurate sensor models"}),": Add noise, motion blur, lens distortion"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Physics tuning"}),": Match friction, contact parameters to real hardware"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Domain randomization"}),": Cover full range of real-world variation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Progressive training"}),": Train in sim \u2192 fine-tune on small real dataset"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"code-example-adding-realistic-camera-noise",children:"Code Example: Adding Realistic Camera Noise"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from omni.isaac.sensor import Camera\n\ncamera = Camera(\n    prim_path="/World/Camera",\n    position=[2, 0, 1],\n    frequency=30,  # 30 FPS\n    resolution=(1920, 1080)\n)\n\n# Add realistic noise and blur\ncamera.add_motion_blur(intensity=0.5)\ncamera.add_noise(mean=0.0, stddev=0.02)  # Gaussian noise\ncamera.set_lens_distortion(k1=-0.1, k2=0.05)  # Barrel distortion\n'})}),"\n",(0,a.jsx)(n.h2,{id:"self-assessment-questions",children:"Self-Assessment Questions"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Why does Isaac Sim require an NVIDIA RTX GPU, whereas Gazebo can run on integrated graphics?"})}),"\n",(0,a.jsx)(i,{children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)("summary",{children:"Answer"}),"\nIsaac Sim uses RTX-accelerated ray tracing for photorealistic rendering and GPU-accelerated PhysX 5 for physics simulation. Ray tracing requires dedicated RT cores (found in RTX GPUs) for real-time performance. GPU physics allows simulating hundreds of objects in parallel, which is impossible on CPU. Gazebo uses CPU-based physics (ODE/Bullet) and basic OpenGL rendering, which runs on any graphics card but limits visual fidelity and simulation scale."]})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"What is domain randomization, and how does it improve sim-to-real transfer?"})}),"\n",(0,a.jsx)(i,{children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)("summary",{children:"Answer"}),"\nDomain randomization varies simulation parameters (lighting, textures, object poses, sensor noise) during training to create diverse synthetic data. Models trained on randomized data learn robust features that work across environments instead of overfitting to specific sim conditions. For example, if trained only on perfect lighting, a detector fails in shadows. By randomizing lighting intensity/color/direction, the model learns to detect objects regardless of illumination, improving real-world performance."]})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"How does USD differ from URDF, and why does Isaac Sim use USD instead?"})}),"\n",(0,a.jsx)(i,{children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)("summary",{children:"Answer"}),"\nUSD (Universal Scene Description) is a composable, layered scene format designed for film/VFX workflows, supporting complex scenes with millions of objects. URDF is robot-specific, limited to kinematic trees, and doesn't scale to large environments. USD allows non-destructive editing (layers override base assets without modification), handles massive datasets, and supports photorealistic materials/lighting. Isaac Sim uses USD because it targets large-scale simulations (warehouses with 100+ robots, detailed objects) which would be impractical in URDF/SDF."]})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:'What types of synthetic data can Isaac Sim generate, and why is "perfect labeling" valuable?'})}),"\n",(0,a.jsx)(i,{children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)("summary",{children:"Answer"}),'\nIsaac Sim generates: (1) RGB images, (2) 2D/3D bounding boxes, (3) Semantic/instance segmentation masks, (4) Depth maps, (5) Surface normals, (6) Optical flow. "Perfect labeling" means ground truth is exact (no human error), which is impossible with manual annotation. For segmentation, every pixel is correctly labeled. For depth, values are physically accurate. This enables training on millions of labeled examples quickly and cheaply, whereas manual labeling is expensive ($0.10-$1/image) and error-prone.']})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"When would you choose Isaac Sim over Gazebo for a robotics project?"})}),"\n",(0,a.jsx)(i,{children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)("summary",{children:"Answer"}),"\nChoose Isaac Sim when: (1) ",(0,a.jsx)(n.strong,{children:"Training vision models"}),"\u2014need photorealistic rendering and synthetic data generation, (2) ",(0,a.jsx)(n.strong,{children:"Large-scale simulation"}),"\u2014simulating 10+ robots simultaneously (Isaac's GPU physics scales better), (3) ",(0,a.jsx)(n.strong,{children:"Perception-heavy tasks"}),"\u2014object detection, segmentation, depth estimation where visual fidelity matters, (4) ",(0,a.jsx)(n.strong,{children:"Commercial deployment"}),"\u2014Isaac SDK provides production-ready, optimized perception stacks. Choose Gazebo for: (1) ",(0,a.jsx)(n.strong,{children:"Lightweight prototyping"}),", (2) ",(0,a.jsx)(n.strong,{children:"Non-vision tasks"})," (path planning, control), (3) ",(0,a.jsx)(n.strong,{children:"Limited hardware"})," (no RTX GPU), (4) ",(0,a.jsx)(n.strong,{children:"Open-source requirement"})," (Isaac Sim is proprietary, though free)."]})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"This week, you discovered the NVIDIA Isaac platform:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Isaac Sim"})," offers photorealistic, GPU-accelerated simulation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"USD"})," is the scene format enabling large-scale environments"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Synthetic data generation"})," with domain randomization reduces manual labeling"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"ROS 2 integration"})," bridges Isaac Sim with existing ROS workflows"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sim-to-real"})," requires careful sensor modeling and domain randomization"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsxs)(n.p,{children:["In Week 9, we dive deeper into ",(0,a.jsx)(n.strong,{children:"Isaac SDK and Sim Integration"}),", exploring Isaac ROS packages for VSLAM (visual SLAM), object detection with pre-trained models, and GPU-accelerated image processing with CUDA-based ROS 2 nodes."]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);