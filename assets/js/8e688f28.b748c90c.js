"use strict";(globalThis.webpackChunkai_robotics_book=globalThis.webpackChunkai_robotics_book||[]).push([[3224],{3554:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"Module-3-ISSAC/week-10-isaac-advanced","title":"Week 10: Advanced Isaac Features","description":"Integrate Nav2 for autonomous navigation, leverage cuMotion for GPU-accelerated path planning, and simulate multiple robots at scale.","source":"@site/docs/Module-3-ISSAC/week-10-isaac-advanced.mdx","sourceDirName":"Module-3-ISSAC","slug":"/Module-3-ISSAC/week-10-isaac-advanced","permalink":"/ai-robotics-book/docs/Module-3-ISSAC/week-10-isaac-advanced","draft":false,"unlisted":false,"editUrl":"https://github.com/ai-robotics/ai-robotics-book/tree/main/docs/Module-3-ISSAC/week-10-isaac-advanced.mdx","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10,"title":"Week 10: Advanced Isaac Features","description":"Integrate Nav2 for autonomous navigation, leverage cuMotion for GPU-accelerated path planning, and simulate multiple robots at scale."},"sidebar":"tutorialSidebar","previous":{"title":"Week 9: Isaac SDK and Sim Integration","permalink":"/ai-robotics-book/docs/Module-3-ISSAC/week-09-isaac-sdk-sim"},"next":{"title":"Week 11: Humanoid Robot Development","permalink":"/ai-robotics-book/docs/Module-4-VLA/week-11-humanoid-development"}}');var o=i(4848),t=i(8453);const s={sidebar_position:10,title:"Week 10: Advanced Isaac Features",description:"Integrate Nav2 for autonomous navigation, leverage cuMotion for GPU-accelerated path planning, and simulate multiple robots at scale."},r="Week 10: Advanced Isaac Features",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Nav2 Integration with Isaac Sim",id:"nav2-integration-with-isaac-sim",level:2},{value:"Nav2 Stack Overview",id:"nav2-stack-overview",level:3},{value:"Launch Nav2 in Isaac Sim",id:"launch-nav2-in-isaac-sim",level:3},{value:"Nav2 Configuration for Bipedal Robots",id:"nav2-configuration-for-bipedal-robots",level:3},{value:"cuMotion: GPU-Accelerated Motion Planning",id:"cumotion-gpu-accelerated-motion-planning",level:2},{value:"What is cuMotion?",id:"what-is-cumotion",level:3},{value:"Using cuMotion with MoveIt 2",id:"using-cumotion-with-moveit-2",level:3},{value:"Code Example: Planning with cuMotion",id:"code-example-planning-with-cumotion",level:3},{value:"Behavior Trees for Complex Tasks",id:"behavior-trees-for-complex-tasks",level:2},{value:"What are Behavior Trees?",id:"what-are-behavior-trees",level:3},{value:"Example: Pick and Place BT",id:"example-pick-and-place-bt",level:3},{value:"Running Behavior Trees with Nav2",id:"running-behavior-trees-with-nav2",level:3},{value:"Multi-Robot Simulation at Scale",id:"multi-robot-simulation-at-scale",level:2},{value:"Isaac Sim Multi-Robot Capabilities",id:"isaac-sim-multi-robot-capabilities",level:3},{value:"Fleet Management with cuOpt",id:"fleet-management-with-cuopt",level:3},{value:"Self-Assessment Questions",id:"self-assessment-questions",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components},{Details:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"week-10-advanced-isaac-features",children:"Week 10: Advanced Isaac Features"})}),"\n",(0,o.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,o.jsx)(n.p,{children:"This week brings together everything you've learned: ROS 2 navigation (Nav2), GPU-accelerated motion planning (cuMotion), and large-scale multi-robot simulation. You'll deploy autonomous navigation stacks, optimize path planning for humanoid robots, and orchestrate warehouse simulations with 50+ robots operating simultaneously\u2014all powered by Isaac's GPU parallelization."}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Integrate"})," Nav2 with Isaac Sim for autonomous mobile robot navigation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Implement"})," cuMotion for collision-free motion planning on manipulators"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Configure"})," behavior trees for complex task execution"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Deploy"})," multi-robot systems with centralized coordination"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Optimize"})," navigation parameters for humanoid bipedal locomotion"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"nav2-integration-with-isaac-sim",children:"Nav2 Integration with Isaac Sim"}),"\n",(0,o.jsx)(n.h3,{id:"nav2-stack-overview",children:"Nav2 Stack Overview"}),"\n",(0,o.jsx)(n.p,{children:"Nav2 (Navigation2) is ROS 2's autonomous navigation framework:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Costmap"}),": 2D grid representing obstacles and free space"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Planner"}),": Global path from start to goal (A*, Theta*, Sm ac Planner)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Controller"}),": Local trajectory following (DWB, TEB, MPPI)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Behavior Server"}),": Recovery behaviors (spin, backup)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Lifecycle Management"}),": State machine for robust startup/shutdown"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"launch-nav2-in-isaac-sim",children:"Launch Nav2 in Isaac Sim"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# launch/nav2_isaac.launch.py\n\nfrom launch import LaunchDescription\nfrom launch.actions import IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch_ros.actions import Node\nimport os\nfrom ament_index_python.packages import get_package_share_directory\n\n\ndef generate_launch_description():\n    nav2_bringup_dir = get_package_share_directory('nav2_bringup')\n    params_file = os.path.join(get_package_share_directory('my_robot_pkg'), 'config', 'nav2_params.yaml')\n\n    return LaunchDescription([\n        # Start Isaac Sim with warehouse environment\n        # (assumed running separately)\n\n        # Nav2 stack\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource(\n                os.path.join(nav2_bringup_dir, 'launch', 'navigation_launch.py')\n            ),\n            launch_arguments={\n                'params_file': params_file,\n                'use_sim_time': 'true',\n            }.items()\n        ),\n    ])\n"})}),"\n",(0,o.jsx)(n.h3,{id:"nav2-configuration-for-bipedal-robots",children:"Nav2 Configuration for Bipedal Robots"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots have different constraints than wheeled robots:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:'# config/nav2_params.yaml\n\ncontroller_server:\n  ros__parameters:\n    controller_frequency: 20.0\n    FollowPath:\n      plugin: "dwb_core::DWBLocalPlanner"\n      min_vel_x: 0.0\n      max_vel_x: 0.5  # Slower than wheeled robots (stability)\n      min_vel_y: -0.2  # Allow lateral movement (humanoids can sidestep)\n      max_vel_y: 0.2\n      max_vel_theta: 0.3  # Slower rotation for balance\n      acc_lim_x: 0.5  # Gentler acceleration\n      acc_lim_y: 0.3\n      acc_lim_theta: 0.5\n      decel_lim_x: -0.5\n      decel_lim_y: -0.3\n      decel_lim_theta: -1.0\n\n      # Footprint (humanoid is taller, narrower)\n      footprint: "[[0.15, 0.15], [0.15, -0.15], [-0.15, -0.15], [-0.15, 0.15]]"\n\n      # Trajectory scoring\n      path_distance_bias: 32.0\n      goal_distance_bias: 24.0\n      occdist_scale: 0.01\n\nplanner_server:\n  ros__parameters:\n    planner_plugins: ["GridBased"]\n    GridBased:\n      plugin: "nav2_smac_planner/SmacPlannerHybrid"  # Hybrid A* for humanoids\n      tolerance: 0.25\n      allow_unknown: true\n      max_iterations: 1000000\n      minimum_turning_radius: 0.4  # Humanoids turn in place easier than cars\n'})}),"\n",(0,o.jsx)(n.h2,{id:"cumotion-gpu-accelerated-motion-planning",children:"cuMotion: GPU-Accelerated Motion Planning"}),"\n",(0,o.jsx)(n.h3,{id:"what-is-cumotion",children:"What is cuMotion?"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)("span",{className:"highlight-purple",children:(0,o.jsx)(n.strong,{children:"cuMotion"})})," is NVIDIA's GPU-accelerated motion planning library:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Collision-free path planning for manipulators"}),"\n",(0,o.jsx)(n.li,{children:"10-100x faster than traditional planners (MoveIt OMPL)"}),"\n",(0,o.jsx)(n.li,{children:"Optimized for complex scenes (thousands of obstacles)"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mermaid",children:"sequenceDiagram\n    participant Dev as Development<br/>(Your PC/Cloud)\n    participant Sim as Isaac Sim<br/>(Validation)\n    participant CI as CI/CD<br/>(Testing)\n    participant Edge as Jetson Orin<br/>(Deployment)\n\n    Note over Dev: Train model on<br/>synthetic data\n    Dev->>Sim: Test in Isaac Sim\n    Sim->>Dev: Validation metrics\n\n    Note over Dev: Export to TensorRT\n    Dev->>CI: Push to repository\n    CI->>CI: Run test suite\n    CI->>Edge: Deploy TensorRT model\n\n    Note over Edge: Real-time inference<br/>(30 FPS)\n    Edge->>Edge: Execute actions\n\n    style Sim fill:#a855f7,stroke:#9333ea,stroke-width:2px,color:#fff\n    style Edge fill:#ec4899,stroke:#db2777,stroke-width:2px,color:#fff\n    style CI fill:#06b6d4,stroke:#0891b2,stroke-width:2px,color:#fff\n"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Diagram:"})," Model deployment workflow from development with synthetic data in Isaac Sim, through CI/CD validation, to real-time TensorRT inference on Jetson edge devices."]}),"\n",(0,o.jsx)(n.h3,{id:"using-cumotion-with-moveit-2",children:"Using cuMotion with MoveIt 2"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Install cuMotion\nsudo apt install ros-humble-curobo\n\n# In your MoveIt config:\n# config/moveit_cpp.yaml\n\nplanning_pipelines:\n  - curobo\n\ncurobo:\n  planning_plugin: curobo_moveit/CuRoboPlanner\n  request_adapters:\n    - default_planning_request_adapters/ResolveConstraintFrames\n    - default_planning_request_adapters/ValidateWorkspaceBounds\n  response_adapters:\n    - default_planning_response_adapters/ValidateSolution\n\n  # cuMotion parameters\n  num_seeds: 16  # Parallel trajectory optimizations\n  interpolation_dt: 0.01  # 100 Hz trajectory\n  collision_check_distance: 0.01  # 1cm safety margin\n"})}),"\n",(0,o.jsx)(n.h3,{id:"code-example-planning-with-cumotion",children:"Code Example: Planning with cuMotion"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom moveit.planning import MoveItPy\nfrom geometry_msgs.msg import PoseStamped\n\n\nclass CuMotionPlanner(Node):\n    def __init__(self):\n        super().__init__(\'curobo_planner\')\n\n        # Initialize MoveIt\n        self.moveit = MoveItPy(node=self)\n        self.arm = self.moveit.get_planning_component("manipulator")\n\n    def plan_to_pose(self, target_pose):\n        """Plan to target pose using cuMotion"""\n\n        # Set planning pipeline to cuMotion\n        self.arm.set_planning_pipeline_id("curobo")\n\n        # Set goal\n        self.arm.set_pose_goal(target_pose)\n\n        # Plan (GPU-accelerated)\n        plan_result = self.arm.plan()\n\n        if plan_result:\n            self.get_logger().info(\'Planning succeeded!\')\n            # Execute\n            self.arm.execute()\n        else:\n            self.get_logger().error(\'Planning failed\')\n\n        return plan_result\n\n\ndef main():\n    rclpy.init()\n    planner = CuMotionPlanner()\n\n    # Define target pose\n    target = PoseStamped()\n    target.header.frame_id = "base_link"\n    target.pose.position.x = 0.5\n    target.pose.position.y = 0.2\n    target.pose.position.z = 0.4\n    target.pose.orientation.w = 1.0\n\n    planner.plan_to_pose(target)\n\n    rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"behavior-trees-for-complex-tasks",children:"Behavior Trees for Complex Tasks"}),"\n",(0,o.jsx)(n.h3,{id:"what-are-behavior-trees",children:"What are Behavior Trees?"}),"\n",(0,o.jsx)(n.p,{children:"Behavior trees (BTs) coordinate multiple actions with logic:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Root\n\u251c\u2500\u2500 Sequence (all must succeed)\n\u2502   \u251c\u2500\u2500 Navigate to Object\n\u2502   \u251c\u2500\u2500 Grasp Object\n\u2502   \u2514\u2500\u2500 Navigate to Goal\n\u2514\u2500\u2500 Fallback (try until one succeeds)\n    \u251c\u2500\u2500 Recovery: Spin\n    \u2514\u2500\u2500 Recovery: Backup\n"})}),"\n",(0,o.jsx)(n.h3,{id:"example-pick-and-place-bt",children:"Example: Pick and Place BT"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-xml",children:'\x3c!-- behavior_tree.xml --\x3e\n\n<root main_tree_to_execute="PickAndPlaceTree">\n  <BehaviorTree ID="PickAndPlaceTree">\n    <Sequence name="PickAndPlace">\n\n      \x3c!-- Navigate to pickup location --\x3e\n      <Action ID="NavigateToPoint"\n              goal="{pickup_location}"\n              server_name="navigate_to_pose"/>\n\n      \x3c!-- Align with object --\x3e\n      <Action ID="AlignWithObject"\n              object_id="{target_object_id}"/>\n\n      \x3c!-- Grasp --\x3e\n      <Action ID="CloseGripper"\n              force="20.0"/>\n\n      \x3c!-- Navigate to drop location --\x3e\n      <Action ID="NavigateToPoint"\n              goal="{dropoff_location}"\n              server_name="navigate_to_pose"/>\n\n      \x3c!-- Release --\x3e\n      <Action ID="OpenGripper"/>\n\n    </Sequence>\n  </BehaviorTree>\n</root>\n'})}),"\n",(0,o.jsx)(n.h3,{id:"running-behavior-trees-with-nav2",children:"Running Behavior Trees with Nav2"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# Load behavior tree\nros2 run nav2_bt_navigator bt_navigator --ros-args \\\n  -p default_bt_xml_filename:=/path/to/behavior_tree.xml\n\n# Send goal through behavior tree\nros2 action send_goal /navigate_to_pose nav2_msgs/action/NavigateToPose \\\n  \"{pose: {header: {frame_id: 'map'}, pose: {position: {x: 2.0, y: 1.0, z: 0.0}}}}\"\n"})}),"\n",(0,o.jsx)(n.h2,{id:"multi-robot-simulation-at-scale",children:"Multi-Robot Simulation at Scale"}),"\n",(0,o.jsx)(n.h3,{id:"isaac-sim-multi-robot-capabilities",children:"Isaac Sim Multi-Robot Capabilities"}),"\n",(0,o.jsx)(n.p,{children:"Isaac Sim can simulate 100+ robots in parallel using GPU acceleration:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'# multi_robot_warehouse.py\n\nfrom omni.isaac.kit import SimulationApp\nsimulation_app = SimulationApp({"headless": False})\n\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nimport numpy as np\n\nworld = World()\nworld.scene.add_default_ground_plane()\n\n# Add warehouse model\nadd_reference_to_stage(\n    usd_path="/Isaac/Environments/Simple_Warehouse/warehouse.usd",\n    prim_path="/World/Warehouse"\n)\n\n# Spawn 50 robots in a grid\nnum_robots = 50\ngrid_size = int(np.sqrt(num_robots))\n\nfor i in range(num_robots):\n    row = i // grid_size\n    col = i % grid_size\n\n    add_reference_to_stage(\n        usd_path="/Isaac/Robots/Carter/carter_v2.usd",\n        prim_path=f"/World/Carter_{i}"\n    )\n\n    # Position in grid (2m spacing)\n    robot = world.scene.get_object(f"Carter_{i}")\n    robot.set_world_pose(position=[row * 2.0, col * 2.0, 0.0])\n\nworld.reset()\n\n# Simulate 1000 steps\nfor _ in range(1000):\n    world.step(render=True)\n\nsimulation_app.close()\n'})}),"\n",(0,o.jsx)(n.h3,{id:"fleet-management-with-cuopt",children:"Fleet Management with cuOpt"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"cuOpt"})," (CUDA Optimization) solves vehicle routing problems on GPU:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from cuopt import routing\n\n# Define depot and delivery locations\ndepot = [0.0, 0.0]\ndeliveries = [[10, 5], [15, 10], [5, 15], [20, 20]]  # 4 delivery points\n\n# Define robot fleet\nnum_robots = 2\nrobot_capacity = 100  # kg\n\n# Solve routing problem\nsolution = routing.solve_vrp(\n    depot=depot,\n    locations=deliveries,\n    num_vehicles=num_robots,\n    vehicle_capacity=robot_capacity,\n    package_weights=[20, 30, 25, 25]  # kg per delivery\n)\n\nprint(f"Route for Robot 1: {solution.routes[0]}")\nprint(f"Route for Robot 2: {solution.routes[1]}")\nprint(f"Total distance: {solution.total_distance:.2f}m")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"self-assessment-questions",children:"Self-Assessment Questions"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsxs)(n.em,{children:[(0,o.jsx)(n.em,{children:"Why is hybrid A"})," better than grid-based A"]})," for humanoid navigation?**"]}),"\n",(0,o.jsx)(i,{children:(0,o.jsxs)(n.p,{children:[(0,o.jsx)("summary",{children:"Answer"}),"\nHybrid A* considers the robot's orientation and kinematic constraints (turning radius, minimum step length) when planning, producing smoother, more feasible paths. Grid-based A* only plans in (x, y) space, ignoring orientation, which can result in paths with sharp turns that bipedal robots cannot execute. Humanoids benefit from hybrid A* because it generates paths compatible with their locomotion capabilities, reducing replanning frequency and improving execution success rate."]})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"How does cuMotion achieve 10-100x speedup over CPU-based planners?"})}),"\n",(0,o.jsx)(i,{children:(0,o.jsxs)(n.p,{children:[(0,o.jsx)("summary",{children:"Answer"}),"\ncuMotion parallelizes trajectory optimization and collision checking across thousands of GPU cores. It evaluates 16-64 candidate trajectories simultaneously, checking collisions against complex meshes in parallel. CPU planners (OMPL) are sequential: evaluate one trajectory, check collisions serially, then try the next. For scenes with 1000+ obstacles and 7-DoF arms, this parallelism translates to massive speedups. Additionally, cuMotion uses GPU-optimized algorithms (parallel distance queries, batched forward kinematics) unavailable on CPU."]})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"What is the advantage of using behavior trees over hardcoded if-else logic for robot tasks?"})}),"\n",(0,o.jsx)(i,{children:(0,o.jsxs)(n.p,{children:[(0,o.jsx)("summary",{children:"Answer"}),"\nBehavior trees are modular, composable, and human-readable. You can build complex behaviors from simple, reusable nodes (Navigate, Grasp, Detect). They handle failures gracefully via Fallback nodes (try alternatives automatically). Debugging is visual (see tree structure), unlike nested if-else code. Modifications don't require recompiling\u2014edit XML and reload. Industry adoption (game AI, robotics) means extensive tooling (BehaviorTree.cpp, Groot visualizer). Hardcoded logic becomes unmaintainable as task complexity grows beyond 5-10 steps."]})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Why can Isaac Sim simulate 100+ robots while Gazebo struggles with 10?"})}),"\n",(0,o.jsx)(i,{children:(0,o.jsxs)(n.p,{children:[(0,o.jsx)("summary",{children:"Answer"}),"\nIsaac Sim uses GPU-accelerated PhysX 5, which parallelizes rigid body dynamics, collision detection, and constraint solving across thousands of GPU cores. Each robot's physics is computed in parallel. Gazebo uses CPU physics (ODE/Bullet) where robots are simulated sequentially. For 100 robots, Gazebo requires 100x more CPU time, dropping to 1-5 FPS. Isaac Sim maintains 60+ FPS by leveraging GPU parallelism. Additionally, Isaac Sim optimizes rendering (instancing, LOD) to handle visual complexity efficiently."]})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"What is the sim-to-real gap for Nav2 navigation, and how do you minimize it?"})}),"\n",(0,o.jsx)(i,{children:(0,o.jsxs)(n.p,{children:[(0,o.jsx)("summary",{children:"Answer"}),"\nThe gap arises from: (1) perfect sensors in sim vs noisy real LIDAR/cameras, (2) ideal physics vs slippery floors/unexpected contacts, (3) exact localization vs SLAM drift. Minimize by: (1) Adding sensor noise in simulation (Gaussian noise on LIDAR/IMU), (2) Domain randomization (vary friction, mass), (3) Testing recovery behaviors in sim (what happens when robot is pushed?), (4) Using realistic costmap inflation (account for real sensor uncertainty), (5) Fine-tuning on real hardware with conservative speed limits initially."]})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Nav2"})," integrates with Isaac Sim for autonomous navigation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"cuMotion"})," accelerates motion planning 10-100x via GPU parallelization"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Behavior trees"})," coordinate complex multi-step tasks"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Multi-robot simulation"})," scales to 100+ robots with GPU physics"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"cuOpt"})," optimizes fleet routing and task allocation"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsxs)(n.p,{children:["Week 11 begins Module 4 (VLA), exploring ",(0,o.jsx)(n.strong,{children:"Humanoid Robot Development"})," with real hardware platforms (Unitree G1), whole-body control, and deploying perception stacks on Jetson Orin Nano."]})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>r});var a=i(6540);const o={},t=a.createContext(o);function s(e){const n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);